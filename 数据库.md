* Transaction
* Data Replication
* Sharding Strategies
* CAP Theorem
* Database Normalization
* Indexes and how they work



# MySQL问题

## 引擎

## 索引

B+树与B-树的区别

***非叶子节点：B树存储数据，B+树只存储索引***

***叶子节点：B树的叶子节点不需要用链表来串联***

#### 🌟什么样的情况下查询不走索引？

1. **范围查询之后的索引查找全部失效**
2. 函数运算会造成索引失效
3. 使用不等号查询会造成索引失效
4. 使用空值查找会造成索引失效（is null不会，但is not null会造成索引失效）
5. 模糊查询中如果百分号在前面会造成索引失效
6. 字符串查询是要加单引号，不然会自动转换成int类型进行全表查询，造成索引失效
7. 误用or造成索引失效

#### 注意一种特殊情况：联合索引（a,b,c） select a and b order by c

是可以走索引的！



# 《MySQL实战45讲》笔记

## 01 MySQL的基础架构：查询操作的执行流程是什么？

主要分为Server层与存储引擎层

Server层：包括连接器、查询缓存、分析器、优化器和执行器。所有跨存储引擎的功能都在这一层来实现，包括存储过程，触发器，视图等。

存储引擎层：默认为innoDB

#### 1、连接器

连接器负责跟客户端建立连接、获取权限、维持和管理连接。

```shell
mysql -h$ip -P$port -u$user -p
```

建立连接后系统会自动读取并设置用户的权限，连接成功后就算管理员更改当前用户的权限也不会对本次连接产生影响，在下次该用户连接时才会发生权限变化。

![截屏2021-01-04 下午6.12.59]( /Users/xiaogengen/Desktop/秋招/MyRoadMap/typora-user-images/截屏2021-01-04 下午6.12.59.png)

使用show processlist；命令可以查看当前连接状态，Sleep表示空闲连接

空闲连接太长时间不操作就会自动断开，通过wait_timeout参数控制，默认为8小时

连接断开后客户端再次发送请求的话就会收到一个错误提醒：Lost connection to MySQL server during query.需要再次重连

数据库中分为长连接和短连接，尽量使用长连接，因为连接操作过程比较复杂。但是使用长连接可能会出现MySQL占用内存太大的情况，因为MySQL在执行过程中临时使用的内存是保存在连接对象里面的，这些资源只有在连接断开时才会释放。所以长期累积可能会造成OOM，现象就是MySQL异常重启了。

解决方法可以考虑：

1. 定期断开长连接
2. 如果使用MySQL5.7或更新版本，可以在执行完一次比较大的操作后使用mysql_reset_connection来重新初始化连接资源。这个过程可以将连接恢复到刚刚创建的状态而不需要重连和权限验证。

#### 2、查询缓存

MySQL8.0之后被删掉了

#### 3、分析器

词法分析与语法分析：词法分析分析出一条MySQL语句中哪个代表操作方法，哪个代表表名哪个代表列名；语法分析负责分析输入的MySQL语句是否有错误。

#### 4、优化器

优化器是在表里面有多个索引的时候选择使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

```mysql
select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;
```

可以先从表1选出c=10的记录的ID值，再根据ID值关联到表2，再从t2中选取d=20

也可以从表2开始关联到表1

优化器会选择这两种方法效率更高的一种来执行。

#### 5、执行器

```mysql
select * from T where ID=10;
```

执行器首先判断用户对表T是否有查询的权限

如果有权限就会调用innoDB引擎，一行一行地判断是否符合查询约束。





## 02 日志系统：更新操作的执行流程是什么？

> 关于日志的问题，请拌以15：日志问题答疑和09、12：什么时候落盘：change buffer与刷脏页，一起食用

创建一个表（主键ID和int字段c）

```mysql
create table t1(ID int primary key, c int);
```

将ID=2的那一行c增1

```mysql
update t1 set c=c+1 where ID=2;
```

#### redo log日志模块

WAL机制：Write Ahead Logging：**先写日志，再写磁盘**

redo日志模块大小固定，使用双指针进行管理：write pos是指要写入的位置，写到末尾后循环到头部，checkpoint是擦除的位置，之前的要保存到磁盘后擦除。

> redo log的存储位置：在内存中创建固定大小的赊账小黑板，写不下了就将check point前的内容擦除并存入磁盘

当write pos追上check pos时就要更新赊账白板更新checkpoint

<img src="https://static001.geekbang.org/resource/image/b0/9c/b075250cad8d9f6c791a52b6a600f69c.jpg" alt="img" style="zoom:60%;" />

#### binlog日志模块

redo log被innoDB设计在存储引擎层，binlog是MySQL自带的Server层中的方式。

redo log是物理日志，存储的是“ID=2位置的c需要更改成1”，而binlog是逻辑日志，会存储更新数据的逻辑“把ID=2位置的c加1”

redo log是固定大小循环写入的，binlog不是，可以一直增加。

#### ⭐️两阶段提交

1. 执行器调用存储引擎的读取接口，获取ID=2这一行的数据。（存储引擎判断这个数据页是否在内存中，如果不在内存中需要取磁盘中获取）
2. 执行器对这行数据进行+1操作，更新完成后调用存储引擎的写接口写入数据。
3. 存储引擎将新数据写入内存，并将新更新写入redo log，此时redo log状态为prepare，存储引擎通知执行器更新已完成，随时可以commit
4. 执行器写binlog，写完后提交
5. 存储引擎提交事务，redo log状态更新为commit

> 至于什么时候将写到内存里面的数据写入到磁盘中，看第12节的flush刷脏页原理。

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108171547642.png)

> 存储引擎负责写redolog，redolog是存储由存储引擎管理存储在内存中的，相当于小赊账板
>
> 而binlog是由MySql Server层管理，由执行器读写的阶段性大日志文件

#### 如何解决数据库崩溃恢复问题？

* 如果出现了误删库😭，需要做的是：

1. 首先找到最近一次的完整的数据库备份（叫**全量备份**），下载成本地临时库
2. 在这个本地临时库执行当时到误删库之前的binlog
3. 提交本地临时库

* **如果执行顺序是redo log prepare-redo log commit-binlog：**

如果在redolog写完之后发生了crash，redo log具有crash-safe可以成功提交更新的数据，但是binlog中没有写入更新数据的操作逻辑，所以在下载了本地临时库再执行binlog时，数据无法完成更新。

* **如果执行顺序是binlog-redo log prepare-redo log commit：**

如果redo log没执行成功就crash，数据不会更新仍是0，那么恢复数据时会执行binlog将数据+1，变成1与***原数据？？？（谁定义的原数据，直接更新不就行了？）***不符。

> 我觉得这里的原数据是指磁盘里本来应该有的数据，存储引擎没更新这条数据，这条数据不应该加一，在恢复时加一了与预期不符合。

* **参数：**

redo log：innodb_flush_log_at_trx_commit设成1的时候所有的数据更新都会直接持久化到磁盘中

binlog：sync_binlog设成1的时候也是一样

建议都设成1



## 03 事务隔离：修改的数据什么时候可以看见？

事务的特性：ACID：Atomically原子性 Consistency一致性  Isolation隔离性 Durability持久性

**事务的隔离性与数据库的效率**是对立权衡的

#### 四种事务隔离：

* 读未提交（Read Uncommitted）：事务A读取事务B未提交的数据。
* 读提交（Read Committed）：事务A读取事物B提交后的数据。***<u>读提交的视图是在SQL语句开始执行时创建的。？？？</u>***
* 可重复读（）：事务A在提交前所看到的数据不变，保持一致。需要在事务A启动时创建视图，之后一直查看这个视图。
* 串行化：设置独占式的读写锁，不允许并行读写

<img src="https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261524691.png" alt="img" style="zoom:50%;" />

以这张图为例：读未提交是在B未提交之前A就可以读到B更新的数据，所以v1v2v3都是2

读提交是在B提交之后A才可以读到B更新的数据，所以v1是1，v2v3是2

可重复读是指在A启动时，就创建一个查询数据的视图，前后数据保持一致，v1v2都是1，在A提交之后，读取v3为2

***串行化？？？***

#### 事务隔离的设置

transaction-isolation参数

#### 事务隔离的实现

#### 事务的启动方式

* 显式地启动事务。begin/start transaction/commit/rollback
* set autocommit=0，关闭掉自动提交，这样我们执行sql语句时，事务自动启动但是不会自动提交，需要手动执行commit或者关闭数据库才会提交

#### 长事务

set autocommit=0会造成select全部都存在事务中，造成长事务

***<u>建议set autocommit=1并且手动进行commit？？？</u>***



> 如何避免长事务？



## B+树

数据库索引

数据库两个最重要的任务：

```mysql
select * from user where id=2;							// 等值查找
select * from user where id>5 and id<=10;		// 区间查找
```

数据库索引主要解决以上两个问题，并且保证执行效率和存储空间。

#### 散列表：

散列表可以实现O(1)的查找速度和更新速度，但是不能实现区间查找

#### 平衡二叉搜索树：

二叉搜索树也可以实现快速的查找，前提是使其保持平衡，虽然中序遍历可以得到从小到大顺序的数据，但是也同样很难实现区间查找

#### 跳表：

跳表是一个很好的的实现方式，等值查找区间查找都可以实现，redis中有很好的跳表区间实现，之后再学习。

#### B+树——改造后的二叉查找树

B+树对二叉查找树进行了一下改造：

* 将二叉查找树中的节点中存储索引，而不是存储数据
* 将二叉查找树的叶子节点用链表进行连接，以满足区间查找

**问题：**将索引存储到二叉查找树节点中，二叉树节点较大（相较于一个索引字符），普通内存很难满足大型数据存储

很简单，将二叉查找树存在磁盘中。

**有问题：**内存的读写速度以纳秒计时，但是磁盘的读写速度只能以毫秒计时，每个节点的访问都对应着一次磁盘IO操作，那么查找一个数据需要的磁盘IO次数就等于树的高度，大大降低了效率，该如何解决？

将二叉查找树改为m叉查找树，比如一个包含16个索引的数据表，二叉查找树的高度为5层，需要4次磁盘IO操作（根节点存储在内存中），但是五叉查找树的高度为3层，只需两次磁盘IO操作。如果是100叉查找树，那么对于1亿条数据也只需要2次磁盘IO操作。

**还有问题：**如何确定m是多少呢？
$$
PAGE SIZE = (m-1)*4[keywords 大小]+m*8[children 大小]
$$
根据磁盘页的大小来确定m的大小，**尽量保证每个节点可以保存在一个页中**，读取一个节点正好需要一次磁盘操作。

```java
/**
 * 这是 B+ 树非叶子节点的定义。
 *
 * 假设 keywords=[3, 5, 8, 10]
 * 4 个键值将数据分为 5 个区间：(-INF,3), [3,5), [5,8), [8,10), [10,INF)
 * 5 个区间分别对应：children[0]...children[4]
 *
 * m 值是事先计算得到的，计算的依据是让所有信息的大小正好等于页的大小：
 * PAGE_SIZE = (m-1)*4[keywordss 大小]+m*8[children 大小]
 */
public class BPlusTreeNode {
  public static int m = 5; // 5 叉树
  public int[] keywords = new int[m-1]; // 键值，用来划分数据区间
  public BPlusTreeNode[] children = new BPlusTreeNode[m];// 保存子节点指针
}
 
/**
 * 这是 B+ 树中叶子节点的定义。
 *
 * B+ 树中的叶子节点跟内部结点是不一样的,
 * 叶子节点存储的是值，而非区间。
 * 这个定义里，每个叶子节点存储 3 个数据行的键值及地址信息。
 *
 * k 值是事先计算得到的，计算的依据是让所有信息的大小正好等于页的大小：
 * PAGE_SIZE = k*4[keyw.. 大小]+k*8[dataAd.. 大小]+8[prev 大小]+8[next 大小]
 */
public class BPlusTreeLeafNode {
  public static int k = 3;
  public int[] keywords = new int[k]; // 数据的键值
  public long[] dataAddress = new long[k]; // 数据地址
 
  public BPlusTreeLeafNode prev; // 这个结点在链表中的前驱结点
  public BPlusTreeLeafNode next; // 这个结点在链表中的后继结点
}

```

<img src=" /Users/xiaogengen/Desktop/秋招/MyRoadMap/typora-user-images/image-20210219110137502.png" alt="image-20210219110137502"  />

 

**还有问题：**如果增加数据使每个节点块数量超过m怎么办？

超过m从下向上分裂，小于m/2就合并***（需要深入理解？？？）***

#### B树/B-树：

**B树存储数据，B+树只存储索引**

**B树的叶子节点不需要用链表来串联**

#### 思考

> B+树叶子节点使用的是单链表还是双向链表？



> 将散列表中的元素使用链表串联起来，是否能够实现区间查找呢？





## 04 数据库索引（上）

#### 索引模式

1. 散列表
2. 有序数组：插入数据很难，适用于静态数据集
3. B+树

#### 主键索引与非主键索引

使用以下建表语言：

```sql
create table t (
id int primary key,
k int not null,
name varchar(20),
index(k))engine=innodb;
```

会创建出两个索引表：

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/20210816170420.png)

* 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。
* 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。

**基于主键索引和普通索引的查询有什么区别？**

基于非主键索引的查询需要多一次回表的过程。 

#### 索引的维护

在插入新索引的时候要进行索引的维护，涉及到索引表的合并和分裂。

#### ⭐️要不要使用自增主键？

设置自增主键语句：

```sql
not null primary key auto_increment
```

1. 从索引表的维护角度来讲**，每增加一行新记录是一个递增插入的操作**。每加入一行都是追加操作，并不涉及到数据的挪动，**不会触发叶子结点数据页的分裂**。如果是业务字段不能保证有序插入。
2. 如果用身份证号号做主键或者是其他字符串类型，非主键索引的叶子节点每个占用的字节数比自增主键更大。主键长度越小，**普通索引的叶子节点就越小，普通索引占用的空间也就越小。**

#### 思考：删除与重建索引

```mysql
alter table T drop index k;
alter table T add index(k);
```

```mysql
alter table T drop primary key;
alter table T add primary key(id);
```

> 这样重建索引的操作是合理的嘛？

这样重建索引目的是好的，但是执行语句不好。因为数据的增删改，索引表可能经历了很多次的分裂与合并，使得产生了许多碎片化的表空间，内存的利用率不高，重新建立索引表是为了让索引更加有序，查找更加快速，空间利用更加合理。

但是不需要这样的执行语句，因为执行下面一句其实已经是删除+重建，使得上面一句的执行是多余的，所以，可以用下面的sql代替：（以后会讲为什么）

```sql
alter table T engine=InnoDB;
```



## 05 索引（下）

![img](https://static001.geekbang.org/resource/image/dc/8d/dcda101051f28502bd5c4402b292e38d.png)

对于上面的表执行以下sql语句：

```sql
select * from t1 where k between 3 and 5;
```

数据库引擎会首先搜索到索引k为3的位置，然后通过k=3对应的主键在数据库中获取数据，然后向后遍历，得到5符合条件再通过主键获取数据，然后向后遍历6不符合结束select。

通过二级索引k定位到主键索引获取数据的方式叫做**回表**， 回表会影响效率，尽量避免。

> 如何减少回表次数提高效率呢？

#### 索引覆盖

比如上面的语句如果改成

```sql
select ID from t1 where k between 3 and 5;
```

这样使用索引k就可以解决。

> 执行这个操作MySQL在表上扫描了多少行？？？没搞懂是个问题

举一个覆盖索引很有用处的例子：在市民信息表中添加一个姓名与ID的联合索引

```sql
create table 'tuser' (
	'id' int(11) not null,
  'id_card' varchar(31) default null,
  'name' varchar(31) default null,
  'age' int(11) default null,
  'ismale' tinyint(1) default null,
  primary key ('id'),
  key 'id_card_name'('id_card','name')
  key 'name'('name')
)engine=innoDB;
```

注意以上是建立一个联合索引使用的语句，可以看到分别建立了关于姓名的索引，和身份证号-姓名的联合索引。

索引太多会影响数据库的性能效率，但是如果这个数据库频繁用到通过身份证号id_card查询name，id_card_name这个联合索引的价值就很大了。

**总结下来使用索引覆盖的含义就是使用联合索引的方式，用索引来代替从数据库中查询数据。（如果都不是主键就要用联合索引，如果通过二级索引查主键就不需要联合索引了）**

但建立索引的消耗与查询频率的权衡，需要DBA的聪明才智。

#### 最左前缀原则

![img](https://static001.geekbang.org/resource/image/89/70/89f74c631110cfbc83298ef27dcd6370.jpg)

联合索引可以通过开头一部分的内容进行左前缀的查询，这样可以提高查询的效率。

比如：查找所有姓张的人的ID：

```sql
select ID from t1 where name like "张%";
```

最左前缀可以是联合索引的最左m个字段，也可以是字符串索引最左m个字符。

可以想到的是这时联合索引的顺序就很重要了。

#### 索引下推

索引下推可以结合最左前缀原则来进行二次筛选：

比如查找所有姓张的，年龄为十岁的男孩的信息：

```sql
select * from tuser where name like "张%" and age=10 and ismale=1;
```

MySQL新加入索引下推的特性可以加快查询过程：

MySQL5.6之前并不会通过联合索引的值判断姓名和年龄，它只会通过姓名来关联主键，然后通过主键查询，需要很多次回表。

MySQL5.6之后加入了索引下推的特性，判断了姓张的人之后还会在联合索引中判断出年龄为10的人，再关联主键查询，减少了很多次回表！！









## 06 全局锁与表锁

#### 1. 全局锁

* 加全局锁的方法：

flush tables with read lock (FTWRL)

* 全局锁的使用场景：做全库逻辑备份

* 给全库加锁的问题：

1. 如果是主库加全局锁，那么整个主库都不能使用系统停摆
2. 如果是从库加全局锁，那么整个加锁期间就接受不到主库传来的binlog

* 那么如何做全局备份呢？

官方自带逻辑备份工具：mysqldump，当mysqldump使用参数--single-transaction的时候，引擎会使用一致性读事务隔离机制生成一致性视图进行备份工作。

但很多数据库表并不支持事务（MyISAM不支持事务，垃圾）

#### 2. 表级别锁

表级别锁和表锁不一样！！Mysql中的表级别锁有两种：表锁和元数据锁（MetaData Lock，MDL）

##### 表锁

```mysql
lock table ... read;
lock table ... write;
```

需要注意，表锁lock table会限制其他线程的读写之外，还会限制本线程接下来的操作。

```sql
lock table t1 read, t2 write;
```

例如这一句，在限制其他线程对t1的写，和对t2的读写之外，也限制了本线程对于表的操作，只能读t1，能读写t2。

##### MDL

MDL的作用是保证读写的正确性，不用自己主动添加，而是数据库自动添加

当一个操作对数据库进行增删改查操作的时候会给表加读锁，当修改数据库表的结构的时候，会加写锁

由于MDL是系统自动加的，所以在使用中有可能会造成许多问题：比如给一个表加一个字段会导致整个库崩溃。

## 07 行锁

行锁：事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成之后才能进行更新

> 有时候描述锁描述得一塌糊涂，简单说人话就是这样子

#### 两阶段锁协议

**在innodb中，行锁不是事务一开始就加上的，而是在需要时加上，并且不会马上释放，而是在事务提交了之后才释放。这个就是两阶段锁协议。**

所以：如果一个事物中需要锁多个行，要把最有可能造成锁冲突，最有可能影响并发度的锁尽量往后放。

#### 死锁与死锁检测

当并发系统中不同的线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

举个死锁的例子！！

![img](/Users/xiaogengen/Desktop/秋招/MyRoadMap/typora-user-images/4d0eeec7b136371b79248a0aed005a52.png)

> 之前举不出死锁的例子是因为不了解两阶段提交的概念，事务A的第一个操作获取第一行的行锁，第二个操作等待第二行的行锁，事务不结束这个锁时不会释放的，而B获取了第二行的行锁等待第一行的行锁，事务不结束也是不会释放的，这样就形成了死锁，两阶段才会形成死锁。

结局死锁的策略有两种：

1. 设置等待锁超时时间：超时时间通过innodb_lock_wait_timeout设置
2. 发起死锁检测：发现死锁后主动回滚死锁链条中的某个事务，方法是将innodb_deadlock_detect设置为on

两种方法各有各的问题：

1. 设置死锁等待超时时间，这个时长不好控制，默认是50s，太长了失去了并发操作的意义，太短的话会把很多普通的锁等待误认为死锁，造成很多操作失效
2. 第二种方法，每新加入一个线程就需要判断新加入之后是否会造成死锁，这个时间复杂度较高On，这样如果并发量较大时会造成CPU占用很高但是执行的事务很少的情况，大多数的CPU资源都被用在了死锁检测上

如何解决热点行的更新的性能问题呢？

1. 关闭死锁检测：emmm

2. 控制并发度：

   1. 在客户端控制，每个客户端限制并发线程数
   2. 消息中间件
   3. 在mysql数据库层面控制并发：修改mysql代码，使对相同行的更新在进入引擎之前排队

3. 将热点行拆成多行

   例如影院余额这一行并发度很高，那就把影院余额这一行拆成十行，余额总额是十行之和。

   当然，不是简单的拆成十行就可以的，还需要很多具体的设计，比如退票功能如果某一行的余额为0就需要加入更多的逻辑。

#### 思考题

如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：

- 第一种，直接执行delete from T limit 10000;
- 第二种，在一个连接中循环执行20次 delete from T limit 500;
- 第三种，在20个连接中同时执行delete from T limit 500。

答案：第二种方式更好一点。

第一种方式，单条语句执行时间比较长，锁的时间也比较长

第三种方式，在20个连接中分别删除会人为造成锁冲突，风险很大



## 08 事务到底是隔离的还是不隔离的

一个重要的例子：

创建一个表：

```mysql
create table t (
id int(11) not null,
k int(11) default null,
primary key (id)
)engine=InnoDB;

# 插入一条数据
insert into t(id, k) values(1,1), (2,2);
```



<img src="/Users/xiaogengen/Desktop/秋招/MyRoadMap/数据库.assets/截屏2021-08-07 上午10.36.24.png" alt="截屏2021-08-07 上午10.36.24"  />

最终结果：A查到的是1，B查到的是3

> 我完全懂了：数据库启动事务的时候会创建一个视图快照，但是启动事务的时机很讲究，如果只是用start transaction或者begin，数据库会在执行第一条innodb查询时启动事务，如果想start trasaction时直接启动事务，就使用start transaction with consistent snapshot方法，数据库会立即开启一个事务并创建一致性视图。
>
> 而对于update操作来说，涉及到”当前读“在正文中介绍。

### 快照在MVCC里是怎样工作的？

#### 1. 数据与事务的多版本

InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。

而且每行数据都有多个版本，每次事务更新数据的时候就会生成新的数据版本，并且将数据行的版本row trx_id与事务transaction id关联起来。

![img](/Users/xiaogengen/Desktop/秋招/MyRoadMap/数据库.assets/68d08d277a6f7926a41cc5541d3dfced.png)

而旧的数据版本的数据，实际上是通过undo log来实现的，比如想要V2版本的数据就要从当前版本V4执行undo log U3和undo log U2得到。

#### 2. 事务一致性视图

 InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。

“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”

### ⭐️更新逻辑：当前读Current Read

**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**

数据库中的所有更新操作都是先读后写：读出当前数据的最新值然后再更新数据。

同时，**在查询操作中如果进行专门的设置也会有当前读的效果**：

```mysql
select k from t where id=1 lock in share mode;
select k from t where id=1 for update;
```

上面两句就是查询数据的当前读，也就是最新版本，区别是**第一条语句加了读锁也就是共享锁，第二条语句加了写锁也就是排它锁。**

### ⭐️更进一步：一致性读、当前读与行锁

![img](/Users/xiaogengen/Desktop/秋招/MyRoadMap/数据库.assets/cda2a0d7decb61e59dddc83ac51efb6e.png)

如果是这种情况，事务C更新的id=1行的k，但是数据并未提交，这时事务B想要对这行数据进行修改和查询时，会发生什么？

这里就涉及到两阶段锁：

> 在innodb中，行锁不是事务一开始就加上的，而是在需要时加上，并且不会马上释放，而是在事务提交了之后才释放。这个就是两阶段锁协议。

所以C虽然对数据进行了更改，但是还没提交，写锁还没有释放，B想获取id=1那行的写锁，会被阻塞，直到C提交了之后B

才会获得到锁，然后进行当前读+更新操作。

**总结：而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。**

### 可重复读和读已提交的区别

- 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
- 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。

## 09 普通索引和唯一索引该如何选择？

> 这里的点是：普通索引是非聚簇索引，而唯一索引是聚簇索引，这一节是关于聚簇索引与非聚簇索引的选择。

想象一个场景：如果要创建一个市民表，每个市民的身份证号都是不一样的，可以将身份证号设置为一个唯一索引，但是身份证号太长了，作为索引可能会影响索引查询的性能，所以可以选择再创建一个普通索引。

该如何选择呢？

![]( /Users/xiaogengen/Desktop/秋招/MyRoadMap/typora-user-images/image-20210729131721717.png)

### 查询操纵的差异

查询k=5位置的这条数据时，我们会在B+树索引结构中首先定位这条数据。在B+树中按层查找，而在一条B+树索引中可以采用二分查找

* 对于唯一索引，我们查找完ID=500这条数据之后，因为只有一条，所以直接结束查找
* 对于普通索引，查询完（5，500）这条数据之后还会向后看，看看还有没有等于500的，没有就结束了。由于对于索引的读取是每次读取磁盘中的一页放在内存里，所以往后找的速度是很快的。除非500是最后一项那很倒霉还要读取一下磁盘，概率很低

所以这两种操作相差无几。*（但是没说回表的问题？？？找到了之后普通索引还会回表呀！！！*

### 更新操作的差异（⭐️change buffer写磁盘方法）

> 之前有说，数据库的操作是WAL：先写日志再写磁盘，我们之前知道了写日志的操作，但是写磁盘的时候也不是老老实实写进去的，而是使用change buffer

#### change buffer原理：

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，**在不影响数据一致性的前提下**，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

#### change buffer merge

将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。

#### 什么条件下可以使用change buffer？

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。

因此，**唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。**

#### 如何使用change buffer向数据库中插入一条新数据？

第一种情况是，**这个记录要更新的目标页在内存中**。这时，InnoDB的处理流程如下：（不用change buffer）

- 对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。

第二种情况是，**这个记录要更新的目标页不在内存中**。这时，InnoDB的处理流程如下：

- 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；（不用change buffer）

- 对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。

  > 只有对于普通索引，并且想写的数据页不在内存中，需要在磁盘中找的话，会用到change buffer。不然，数据都在内存里了就可以直接读写，或者说唯一索引的插入需要将磁盘里所有索引数据都读入内存中，在内存中也不用费心弄change buffer

将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。

#### change buffer适合的应用场景

change buffer在每个数据页被读进内存的时候会执行merge操作。更新操作还是会稍微费时的，对buffer空间的利用率也不高，如果想发挥change buffer的效率，我们每次在执行merge之前要尽可能在buffer空间内攒足够多的更新操作。

所以change buffer适用于写多读少的场景。

### 所以要怎么选？

回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。

如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能。

### change buffer和redo log

执行以下操作：

```mysql
insert into t(id,k) values(id1,k1),(id2,k2);
```

向表中插入两行，假设k1在内存中，k2不在内存中

那么执行的操作是：

1. 直接向内存中的表中插入(id1, k1)
2. 在change buffer中记录要想k2所在表插入(id2, k2)
3. redo log记录上面两个操作

然后再把这两条数据读出来的时候，由于k1只是存储在内存中可以直接读出。

k2不在内存中，读操作会将k2对应的页从磁盘中读出，并根据change buffer来进行更新，并返回正确的数据。

**redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。**

> 所以change buffer和redo log的功能不是很一样，但是都是为了减少向磁盘读写时的开销。







## 12 为什么有的时候数据库会“抖”一下

**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”**。

### 1. 什么情况会引发数据库的flush过程呢？

1. 第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。

   这个场景，对应的就是InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。

2. 第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。

   这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。

   你一定会说，这时候难道不能**直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？这里其实是从性能考虑的**。如果刷脏页一定会写盘（***以这个为前提***），就保证了每个数据页有两种状态：

   - 一种是内存里存在，内存里就肯定是正确的结果，直接返回；
   - 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。
     这样的效率最高。

   > 这样存储数据比较省事，而且不易出错，保证内存中的数据和磁盘中的数据至少一个是对的，不用在磁盘中存错的内存中没有，然后用redo log来纠正这个数值，这样很麻烦也容易出错。

3. 第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。

   这种场景，对应的就是MySQL认为系统“空闲”的时候。

4. 第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。

   这种场景，对应的就是MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

### 2. 以上的情况对数据库性能的影响

第一种是“redo log写满了，要flush脏页”，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。

第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。**InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：**

- 第一种是，还没有使用的；
- 第二种是，使用了并且是干净页；
- 第三种是，使用了并且是脏页。

InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，第一种情况：未被使用的页面很少。

接下来就是选择要舍弃干净页还是脏页，干净页在内存中能直接使用很方便，所以尽量别舍弃。

把脏页写进磁盘然后刷掉就好了！

刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：

1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
2. 日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。***（？？？这个是什么？为什么要写日志？？）***

### 3. InnoDB的刷脏页控制策略

首先，你要正确地告诉InnoDB所在主机的IO能力，这样InnoDB才能知道需要全力刷脏页的时候，可以刷多快。

这个能力，就是磁盘性能的“全力”，但是我们不能把全力都用来刷脏页，接下来，就要考虑InnoDB怎么控制引擎按照“全力”的百分比来刷脏页。

**设计策略控制刷脏页的速度，会参考哪些因素呢？**

如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是redo log写满。

参数innodb_max_dirty_pages_pct是脏页比例上限，默认值是75%

***具体的计算逻辑以后再看吧，暂时理解不了？？？***

InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，**无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句**，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。

#### 一个会影响刷脏页性能的MySQL机制：

一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：**在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉**；还可以继续蔓延！

找“邻居”这个优化在机械硬盘时代是很有意义的，可以**减少很多随机IO**。机械硬盘的随机IOPS一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。

而如果使用的是SSD这类**IOPS比较高的设备**的话，我就建议你把innodb_flush_neighbors的值设置成0。因为这时候IOPS往往不是瓶颈，而“**只刷自己**”，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。

在MySQL 8.0中，innodb_flush_neighbors参数的**默认值已经是0**了。

#### 思考：

一个内存配置为128GB、innodb_io_capacity设置为20000的大规格实例，正常会建议你将redo log设置成4个1GB的文件。

但如果你在配置的时候不慎将**redo log**设置成了1个100M的文件，会发生什么情况呢？又为什么会出现这样的情况呢？





## 15 关于日志和索引的答疑

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261530327.jpg)

> 首先要仔仔细细地记住这样图，这个是MySQL Innodb引擎更新一行数据时的执行流程，两阶段提交非常重要。需要特殊注意的是，redo log是由innoDB引擎来管理控制，bin log是由MySQL引擎来控制。先写redo log，再写bin log，崩溃恢复机制也要知道，如果出现了崩溃要如何解决。

### 两阶段提交的不同时刻，发生crash要如何处理？

1. 时刻A：

   redo log写了还没提交，bin log还没写，就崩溃了，这时候恢复之后事务会回滚。bin log还没写也不会传到备库里。

2. 时刻B：

   bin log都写完了，就差最后commit但是crash了。怎么办？

   崩溃恢复了之后， 如何判断之前crash的是已经执行到那一步了呢？

   * 如果redo log里面的事务是完整的，也就是说在写那个事务的时候已经写入的commit标识，那就直接commit继续写
   * 如果redo log里面的事务只写到了prepare，就要判断binlog中的事务记录是否完整：
     1. 如果完整，则继续commit
     2. 否则回滚。

   这里面的时刻B属于第二种的第二个情况，redo log写到prepare，binlog没写完，要回滚。

> 这个恢复机制有够难理解
>
> 总结一下😁：
>
> 首先要说一下redo log的崩溃恢复机制问题，redo log之所以可以崩溃恢复，是因为在存储引擎层负责着写内存的工作，并且有undo log的保护，如果发生崩溃，在存储引擎层redo log可以将事务回滚。
>
> 但是redo log一旦commit之后，数据就不能回滚了
>
> 所以两阶段提交中，redo log会先写内存，然后等待binlog写，binlog写完之后它再commit，这次更新操作就算执行成功了，内存中的数据也不用再回滚了。
>
> 在这个过程中，如果发生了crash，要不要回滚其实要看binlog小老弟写完没，如果redo log写完了在prepare状态，binlog还没写，要回滚，因为redo log提交了内存就变了，用bin log恢复的数据中没有最新的，所以要回滚。如果binlog已经写了，就要判断binlog写到什么程度，如果commit都写完了（但是redo log自己还没来得及commit），那就提交了更改就好，如果还没写完，就还得回滚。所以主要看binlog。

#### redo log 和 binlog是怎么关联起来的?

它们有一个共同的数据字段，叫XID。崩溃恢复的时候，会按顺序扫描redo log：

- 如果碰到既有prepare、又有commit的redo log，就直接提交；
- 如果碰到只有parepare、而没有commit的redo log，就拿着XID去binlog找对应的事务。

#### 为什么redo log是prepare状态，bin log是commit状态，重启的时候就能直接提交了？这样能保证主从一致吗？

bin log就是用来更新备库的，（或者是找出最近的一次备份来恢复主库，备库主要就是干这个的），bin log如果写到了commit备库就可以通过这个bin log写数据了，主库也用这个binlog来更新，主库和备库还是一致的。

#### 可不可以redo log和binlog自己写自己的，不用两阶段提交，然后恢复的时候只有两边都写到commit了才能恢复呢？

redo log如果commit了之后，innodb引擎这边就不能回滚了。如果redo log不管binlog写没写完就commit了，崩溃的时候binlog如果没写完，但是redolog这边提交了，两边就不一样了。

#### 如果只用binlog不用redolog行不行？

binlog没有崩溃恢复机制

#### 如果只用redo log不用binlog行不行？

因为binlog有着redo log无法替代的功能。

一个是归档。redo log是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log也就起不到归档的作用。

一个就是MySQL系统依赖于binlog。binlog作为MySQL一开始就有的功能，被用在了很多地方。其中，MySQL系统高可用的基础，就是binlog复制。

## 20 幻读！怎么办！

```mysql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```

### 什么是幻读？

我们要对这个数据库进行一条查询：

```mysql
begin;
select * from t where d=5 for update;
commit;
```

加写锁查询d=5这一行的数据

如果出现以下的情况，查询就会变得很奇怪：

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261044217.png)

其中，我们insert一条新的d=5的行，第三次查询出的问题就叫做幻读：

**幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。**

这里，我需要对“幻读”做一个说明：

1. **在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。**

   > 可重复读隔离级别中，所有更新操作都是当前读，查询想要看到最新数据的话可以使用加锁
   >
   > select ... for update/select ... in shared mode一个是排它锁一个是共享锁

2. 上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。

### 幻读会造成什么问题？

#### 1. 对某一行的锁语义上失效

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261044263.png)

当我们使用select ... id=5 for update的意思是：”在事务提交之前我要锁住d=5这一行“，但是之后事务B将id=1这一行的d改成5，事务C插入了一条d=5的数据，完全没把这个行锁看在眼里，用各自的方式让它的flag没有实际作用。

#### 2. 造成数据不一致问题（严重）

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261044774.png)

我们记住数据库初始的样子：

| id   | c    | d    |
| ---- | ---- | ---- |
| 0    | 0    | 0    |
| 5    | 5    | 5    |
|      |      |      |

T1：事务A对d=5这一行加行锁，并将d从5改成100，但由于两阶段锁协议，这个更新操作在事务提交之前并没有写进bin log中。

T2：随后B更新id=0这一行，不涉及锁冲突，将这行的d改成5，并将c改成5

T3：当前读，获取数据的最新版本（0，5，5）、（5，5，100），然后锁住d=5这一行（读出（0，5，5））

T4：加入一行（1，1，5）

T5：再次锁住读取d（读出（0，5，5）和（1，5，5）)

T6：事务A提交，将更新写入bin log

所以，经过T6，binlog里面应该包含如下操作：

```mysql
1. update t set d=5 where id=0;
2. update t set c=5 where id=0;
3. insert into t values(1,1,5);
4. update t set c=5 where id = 1;
5. update t set d=100 where d=5;
```

手写执行一遍，最终得到结果：

| id   | c    | d    |
| ---- | ---- | ---- |
| 0    | 5    | 100  |
| 5    | 5    | 100  |
| 1    | 5    | 100  |

结果很可怕！

> 这个例子的精髓就是抓住两阶段锁提交时才会写入binlog的问题，A虽然第一步声明说要把d=5这一行改成100，但是没提交，这中间事务B和事务C通过各自的方法又创造出了两条d=5的数据行，最终A的操作把三行都改成了100

如果我们对所有行都加锁，事务A在执行的时候对所有需要扫描的行都加锁，情况如何呢？

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261044089.png)

由于session A把所有的行都加了写锁，所以session B在执行第一个update语句的时候就被锁住了。需要等到T6时刻session A提交以后，session B才能继续执行。

最终binlog中的执行顺序为：

```mysql
1. insert (1,1,5)
   update t set c=5 where id=1;  # #(0,0,0) (5,5,100) (1,5,5)
2. update d=100 where d=5; #(0,0,0) (5,5,100) (1,5,100)
3. update t set d=5 where id=0; # (0,0,5) (5,5,100) (1,5,100)
4. update t set c=5 where id=0; # (0,5,5) (5,5,100) (1,5,100)
```

> 这次虽然我们对所有要扫描到的行都加了锁，但是T3加锁的时候新insert的那一行还不存在，所以就加不上锁，就又出现了一个d=5的新行

### 如何解决幻读？

#### 间隙锁（Gap Lock）

间隙锁锁的是间隙，不允许有其他人向一个间隙中间插入数据

但是间隙锁与我们之前了解到的读锁和写锁，之间存在互斥关系不一样

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261044602.png)

比如这个情况，对于我们之前的数据状态，是没有c=7这行数据的，所以事务A是给（5，10）这个间隙加锁，不允许在查的过程中又有另外一个事务插入了一条c=7的数据，而事务B也是对这个间隙加锁，**这两个事务都是为了保护（5，10）这个间隙，所以不存在竞争关系**。

间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。也就是说，我们的表t初始化以后，如果用select * from t for update要把整个表所有记录锁起来，就形成了7个next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。



## 21 详解加锁

### 两个原则、两个优化和一个bug

1. 原则1：加锁的基本单位是Next-Key Lock，是一个左开右闭的区间
2. 原则2：查找过程中访问到的对象才会加锁（？？？）
3. 优化1：如果是在唯一索引上做等值查询，那么next-key lock退化成行锁
4. 优化2：索引上的等值查询，如果向右遍历且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁(？？？)
5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止

### 实例讲解！

还是按照上次的表来：

#### 案例一：等值查询间隙锁

![img](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261043286.png)

由于表中没有7这条数据，我们通过之前的规则进行判断：

1. 根据原则1，加锁的基本单位是next-key lock，事务A加锁范围是（5,10]
2. 根据优化2，如果是一个等值查询，向右遍历到最后一个不满足条件，next-key lock退化成间隙锁

因此最终加锁的范围是（5,10）

所以我们在给id=8进行插入的时候会被阻塞，但是id=10的位置不会被阻塞。

#### 案例二：

![截屏2021-08-19 上午10.46.03](https://raw.githubusercontent.com/Xiaogengenme/ImagesResource/main/202108261043312.png)





## 23 MySQL如何保证redo log和bin log的完整性？

这节有点细节侥幸感觉面试不会问到，以后再看
